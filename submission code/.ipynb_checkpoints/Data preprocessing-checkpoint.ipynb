{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec4b939",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0bc88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import langdetect\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44ec548",
   "metadata": {},
   "source": [
    "# Product Reviews Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f222e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original length of df:  39015\n",
      "After drop length:  37889\n"
     ]
    }
   ],
   "source": [
    "#Removing rows where columns rating and content contains NA\n",
    "df = pd.read_csv('product_reviews.csv',header=0)\n",
    "print(\"Original length of df: \", len(df))\n",
    "df = df.dropna(subset=['review_rating', 'review_content'])\n",
    "print(\"After drop length: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e22ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the entire dataset for only english\n",
    "df['Language'] = df['review_content'].apply(lambda x: langdetect.detect(x))\n",
    "filtered_en = df.loc[df['Language'] == 'en']\n",
    "print(\"Length of english reviews: \", len(filtered_en))\n",
    "filtered_en.to_csv(\"filtered_reviews.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd61a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test dataset\n",
    "filtered_en = pd.read_csv(\"filtered_reviews.csv\",header=0)\n",
    "train, test = train_test_split(filtered_en, test_size=0.1)\n",
    "rating = np.array(train['review_rating'])\n",
    "#Use ratings as sentiment (positive, negative, neutral) for train dataset\n",
    "sentiment = []\n",
    "for i in range(len(rating)):\n",
    "    if rating[i] < 3:\n",
    "        sentiment.append(\"negative\")\n",
    "    elif rating[i] > 3:\n",
    "        sentiment.append(\"positive\")\n",
    "    else:\n",
    "        sentiment.append(\"neutral\")\n",
    "        \n",
    "train['sentiment'] = sentiment\n",
    "train = train[['product_name','review_content','sentiment']]\n",
    "train.to_csv(\"train_data.csv\", index=False)\n",
    "test = test[['product_name','review_content', 'review_rating']]\n",
    "test.to_csv(\"test_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92dbbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (1.21.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from transformers) (3.4.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
      "Collecting tokenizers!=0.11.3,>=0.10.1\n",
      "  Downloading tokenizers-0.11.5-cp38-cp38-win_amd64.whl (3.3 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\anaconda\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\anaconda\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\lib\\site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.4.0 sacremoses-0.0.47 tokenizers-0.11.5 transformers-4.16.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers requests pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2f9b3c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8012793721595832"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inter-annotator Agreement (Cohen-Kappa score)\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "test_df = pd.read_csv(\"test_data.csv\",header=0)\n",
    "labeler1 = np.array(test_df[\"Annotator_1\"])\n",
    "labeler2 = np.array(test_df[\"Annotator_2\"])\n",
    "cohen_kappa_score(labeler1, labeler2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bd7613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from textblob import Word\n",
    "#Removing stopwords, apply lowercase, remove other symbols, lemmatize\n",
    "dataset = ['train_data','test_data']\n",
    "for ds in dataset:\n",
    "    df = pd.read_csv(\"{}.csv\".format(ds))\n",
    "    df['review_content'] = df['review_content'].apply(lambda x: \" \".join(x.lower() for\n",
    "    x in x.split()))\n",
    "    df['review_content'] = df['review_content'].str.replace('[^\\w\\s]', \"\")\n",
    "    stop = stopwords.words('english')\n",
    "    df['review_content'] = df['review_content'].apply(lambda x: \" \".join(x for x in\n",
    "    x.split() if x not in stop))\n",
    "    df['review_content'] = df['review_content'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "    df.to_csv(\"{}_Processed.csv\".format(ds),index=False)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5367b03b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
